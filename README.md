# Руководство по созданию и управлению контейнерами и виртуальными машинами на базе Virtuozzo

## Содержание
1. [Введение в виртуализацию](#Введение-в-виртуализацию)
  - [Эмуляция оборудования](#Эмуляция-оборудования)
  - [Полная виртуализация](#Полная-виртуализация)
  - [Паравиртуализация](#Паравиртуализация)
  - [Виртуализация уровня операционной системы](#Виртуализация-уровня-операционной-системы)
  - [Virtuozzo — объединение технологий виртуализации уровня ОС и полной виртуализации](#virtuozzo--объединение-технологий-виртуализации-уровня-ОС-и-полной-виртуализации)
2. [Краткая история проекта Virtuozzo](#Краткая-история-проекта-virtuozzo)
3. [Установка и подготовительные действия](#Установка-и-подготовительные-действия)
  - [Установка Virtuozzo с помощью ISO-образа (bare-metal installation)](#Установка-virtuozzo-с-помощью-iso-образа-bare-metal-installation)
  - [Установка Virtuozzo на заранее установленный дистрибутив](#Установка-virtuozzo-на-заранее-установленный-дистрибутив)
  - [Подготовительные действия](#Подготовительные-действия)
4. [Управление шаблонами гостевых ОС](#Управление-шаблонами-гостевых-ОС)
5. [Создание и настройка контейнеров](#Создание-и-настройка-контейнеров)
  - [Конфигурационные файлы](#Конфигурационные-файлы)
  - [Создание контейнера](#Создание-контейнера)
  - [Настройка контейнера](#Настройка-контейнера)
  - [Запуск и вход](#Запуск-и-вход)
6. [Управление контейнерами](#Управление-контейнерами)
  - [Управление состоянием контейнера](#Управление-состоянием-контейнера)
  - [Клонирование контейнера](#Клонирование-контейнера)
  - [Запуск команд в контейнере с хост-ноды](#Запуск-команд-в-контейнере-с-хост-ноды)
  - [Расширенная информация о контейнерах](#Расширенная-информация-о-контейнерах)
7. [Управление ресурсами](#Управление-ресурсами)
  - [Дисковые квоты](#Дисковые-квоты)
  - [Процессор](#Процессор)
  - [Операции ввода/вывода](#Операции-вводавывода)
  - [Память](#Память)
  - [Мониторинг ресурсов](#Мониторинг-ресурсов)
8. [Миграция контейнеров](#Миграция-контейнеров)
9. [Ссылки](#Ссылки)
10. [Лицензия](#Лицензия)

## Введение в виртуализацию
Виртуализация — предоставление наборов вычислительных ресурсов или их логического объединения, абстрагированное от аппаратной реализации, и обеспечивающее изоляцию вычислительных процессов.

Виртуализацию можно использовать в:
* консолидации серверов (позволяет мигрировать с физических серверов на виртуальные, тем самым увеличивается коэффициент использования аппаратуры, что позволяет существенно сэкономить на аппаратуре, электроэнергии и обслуживании)
* разработке и тестировании приложений (возможность одновременно запускать несколько различных ОС, это удобно при разработке кроссплатформенного ПО, тем самым значительно повышается качество, скорость разработки и тестирования приложений)
* бизнесе (использование виртуализации в бизнесе растет с каждым днем и постоянно находятся новые способы применения этой технологии, например, возможность безболезненно сделать снапшот)
* организации виртуальных рабочих станций (так называемых "тонких клиентов")

*Общая схема взаимодействия виртуализации с аппаратурой и программным обеспечением*
![Общая схема взаимодействия виртуализации с аппаратурой и программным обеспечением](https://raw.githubusercontent.com/Amet13/virtuozzo-tutorial/master/images/virt-scheme.png)

Понятие виртуализации можно условно разделить на две категории:
* виртуализация платформ, продуктом этого вида виртуализации являются виртуальные машины
* виртуализация ресурсов преследует целью комбинирование или упрощение представления аппаратных ресурсов для пользователя и получение неких пользовательских абстракций оборудования, пространств имен, сетей

Взаимодействие приложений и операционной системы (ОС) с аппаратным обеспечением осуществляется через абстрагированный слой виртуализации.

Существует несколько подходов организации виртуализации:
* эмуляция оборудования (QEMU, Bochs, Dynamips)
* полная виртуализация (KVM, HyperV, VirtualBox)
* паравиртуализация (Xen, L4, Trango)
* виртуализация уровня ОС (LXC, Virtuozzo, Jails, Solaris Zones)

### Эмуляция оборудования
Эмуляция аппаратных средств является одним из самых сложных методов виртуализации.
В то же время главной проблемой при эмуляции аппаратных средств является низкая скорость работы, в связи с тем, что каждая команда моделируется на основных аппаратных средствах.

В эмуляции оборудования используется механизм динамической трансляции, то есть каждая из инструкций эмулируемой платформы заменяется на заранее подготовленный фрагмент инструкций физического процессора.

Однако метод позволяет использовать виртуализированные аппаратные средства еще до выхода реальных.
Например, управление неизмененной ОС, предназначенной для PowerPC на системе с ARM процессором.

*Эмуляция оборудования моделирует аппаратные средства*
![Схема эмуляции оборудования](https://raw.githubusercontent.com/Amet13/virtuozzo-tutorial/master/images/emulation.png)

### Полная виртуализация
Полная виртуализация использует гипервизор, который осуществляет связь между гостевой ОС и аппаратными средствами физического сервера.
В связи с тем, что вся работа с гостевой операционной системой проходит через гипервизор, скорость работы данного типа виртуализации ниже чем в случае прямого взаимодействия с аппаратурой.
Основным преимуществом является то, что в ОС не вносятся никакие изменения, единственное ограничение — операционная система должна поддерживать основные аппаратные средства.

*Полная виртуализация использует гипервизор*
![Схема полной виртуализации](https://raw.githubusercontent.com/Amet13/virtuozzo-tutorial/master/images/full-virt.png)

Полная виртуализация возможна исключительно при условии правильной комбинации оборудования и программного обеспечения.

### Паравиртуализация
Паравиртуализация имеет некоторые сходства с полной виртуализацией.
Этот метод использует гипервизор для разделения доступа к основным аппаратным средствам, но объединяет код, касающийся виртуализации, в непосредственно операционную систему, поэтому недостатком метода является то, что гостевая ОС должна быть изменена для гипервизора.
Но паравиртуализация существенно быстрее полной виртуализации, скорость работы виртуальной машины приближена к скорости реальной, это осуществляется за счет отсутствия эмуляции аппаратуры и учета существования гипервизора при выполнении системных вызовов в коде ядра.
Вместо привилегированных операций совершаются гипервызовы обращения ядра гостевой ОС к гипервизору с просьбой о выполнении операции.

*Паравиртуализация разделяет процесс с гостевой ОС*
![Схема паравиртуализации](https://raw.githubusercontent.com/Amet13/virtuozzo-tutorial/master/images/paravirt.png)

В паравиртуальном режиме (PV) оборудование не эмулируется, и гостевая операционная система должна быть специальным образом модифицирована для работы в таком окружении.
Начиная с версии 3.0, ядро Linux поддерживает запуск в паравиртуальном режиме без перекомпиляции со сторонними патчами.
Преимущество режима паравиртуализации состоит в том, что он не требует поддержки аппаратной виртуализации со стороны процессора, а также не тратит вычислительные ресурсы для эмуляции оборудования на шине PCI.

Режим аппаратной виртуализации (HVM), который появился в Xen, начиная с версии 3.0 гипервизора требует поддержки со стороны оборудования.
В этом режиме для эмуляции виртуальных устройств используется QEMU, который весьма медлителен несмотря на паравиртуальные драйвера.
Однако со временем поддержка аппаратной виртуализации в оборудовании получила настолько широкое распространение, что используется даже в современных процессорах лэптопов.

### Виртуализация уровня операционной системы
Виртуализация уровня операционной системы отличается от других.
Она использует технику, при которой сервера виртуализируются непосредственно над ОС.
Недостатком метода является то, что поддерживается одна единственная операционная система на физическом сервере, которая изолирует контейнеры друг от друга.
Преимуществом виртуализации уровня ОС является "родная" производительность.

*Виртуализация уровня ОС изолирует серверы*
![Схема виртуализации уровня ОС](https://raw.githubusercontent.com/Amet13/virtuozzo-tutorial/master/images/cont-virt.png)

Виртуализация уровня ОС — метод виртуализации, при котором ядро операционной системы поддерживает несколько изолированных экземпляров пространства пользователя вместо одного.
С точки зрения пользователя эти экземпляры полностью идентичны реальному серверу.
Для систем на базе UNIX эта технология может рассматриваться как улучшенная реализация механизма chroot.
Ядро обеспечивает полную изолированность контейнеров, поэтому программы из разных контейнеров не могут воздействовать друг на друга.

### Virtuozzo — объединение технологий виртуализации уровня ОС и полной виртуализации
Virtuozzo позволяет создавать множество защищенных, изолированных друг от друга контейнеров на одном узле.
Помимо этого возможно создание виртуальных машин на базе QEMU/KVM.
Управление контейнерами и виртуальными машинами происходит с помощью специализированных утилит.

Каждый контейнер ведет себя так же, как автономный сервер и имеет собственные файлы, процессы, сеть (IP адреса, правила маршрутизации).
В отличие от KVM или Xen, Virtuozzo использует одно ядро, которое является общим для всех виртуальных сред.

Контейнеры можно разделить на две составляющие:
* ядро (namespaces, cgroups, CRIU, ploop, vcmmd...)
* пользовательские утилиты (prlctl, vzctl, vzpkg, vzlist, vzdump...)

Namespaces — пространства имен.
Это механизм ядра, который позволяет изолировать процессы друг от друга. Изоляция может быть выполнена в шести контекстах (пространствах имен):
* mount — предоставляет процессам собственную иерархию файловой системы и изолирует ее от других таких же иерархий по аналогии с chroot
* PID — изолирует идентификаторы процессов (PID) одного пространства имен от процессов с такими же идентификаторами другого пространства
* network — предоставляет отдельным процессам логически изолированный от других стек сетевых протоколов, сетевой интерфейс, IP-адрес, таблицу маршрутизации, ARP и прочие реквизиты
* IPC — обеспечивает разделяемую память и взаимодействие между процессами
* UTS — изоляция идентификаторов узла, таких как имя хоста (hostname) и домена (domain)
* user — позволяет иметь один и тот же набор пользователей и групп в рамках разных пространств имен, в каждом контейнере могут быть свой
root и любые другие пользователи и группы

CGroups (Control Groups) — позволяет ограничить аппаратные ресурсы некоторого набора процессов.
Под аппаратными ресурсами подразумеваются: процессорное время, память, дисковая и сетевая подсистемы.
Набор или группа процессов могут быть определены различными критериями.
Например, это может быть целая иерархия процессов, получающая все лимиты родительского процесса.
Кроме этого возможен подсчет расходуемых группой ресурсов, заморозка (freezing) групп, создание контрольных точек (checkpointing) и их перезагрузка.
Для управления этим полезным механизмом существует специальная библиотека libcgroups, в состав которой входят такие утилиты, как cgcreate, cgexec и некоторые другие.

CRIU (Checkpoint/Restore In Userspace) — обеспечивает создание контрольной точки для произвольного приложения, а также возобновления работы приложения с этой точки.
Основной целью CRIU является поддержка миграции контейнеров.
Уже поддерживаются такие объекты как процессы, память приложений, открытые файлы, конвейеры, IPC сокеты, TCP/IP и UDP сокеты, таймеры, сигналы, терминалы, файловые дескрипторы.
В разработке также находится миграция TCP соединений.

vcmmd (Virtuozzo containers memory management daemon) — сервис управления механизмом memory cgroups в пространстве пользователя.
Менеджер памяти 4 поколения управляет memory cgroups.
memory cgroups присутстсвует в ванильном ядре, поэтому не требует сторонних патчей со стороны Virtuozzo.

Проведенные тестирования показывают, что OpenVZ (ныне Virtuozzo) является одним из наиболее актуальных решений на рынке виртуализации, так как показывает внушительные результаты в различных тестированиях.

*График времени отклика системы*
![Время отклика системы](https://raw.githubusercontent.com/Amet13/virtuozzo-tutorial/master/images/response-time.png)

На графике времени отклика системы можно наблюдать результаты трех тестов — с нагрузкой на систему и виртуальную машину, без нагрузки на систему и ВМ, с нагрузкой на ВМ и без нагрузки на систему.
Во всех тестах OpenVZ показал результаты наименьшего времени отклика, в то время, когда ESXi и Hyper-V показывают оверхед 700-3000%, когда у OpenVZ всего 1-3%.

*График пропускной способности сети*
![Пропускная способность сети](https://raw.githubusercontent.com/Amet13/virtuozzo-tutorial/master/images/network.png)

На втором графике — результаты тестирования пропускной способности сети.
На графике можно наблюдать, что OpenVZ обеспечивает практическую нативную пропускную способность 10Gb сети (9.7Gb отправка и 9.87Gb прием).

## Краткая история проекта Virtuozzo
В 1999 году возникла идея создания Linux контейнеров, а уже в 2002 году компания SWsoft представила первый релиз коммерческой версии Virtuozzo. В том же 2002 году появились первые клиенты в Кремниевой долине.

В 2004 году выпуск Virtuozzo для Windows.
В 2005 году было принято решение о разделении Virtuozzo на два отдельных проекта, свободный OpenVZ (под лицензией GNU GPL) и проприетарный Virtuozzo.

В 2006 году OpenVZ стал доступен для Debian Linux, переход к ядру RHEL4.
В 2007 году портирован на RHEL5.

В 2011 году появилась идея создания проекта CRIU, OpenVZ портирован на RHEL6.
В 2012 году стала доступна CRIU v0.1.

В конце 2014 года компания Odin анонсировала открытие кодовой базы Parallels Cloud Server и объединение ее с открытым OpenVZ.

В апреле 2015 года был открыт репозиторий с ядром RHEL7 (3.10), в мае были открыты исходные коды пользовательских утилит, а в июне выложены тестовые сборки ISO-образов и RPM-пакеты.

## Установка и подготовительные действия
Существует два способа установки Virtuozzo:
* с помощью ISO-образа дистрибутива
* с помощью установки пакетов и ядра на заранее установленный дистрибутив

### Установка Virtuozzo с помощью ISO-образа (bare-metal installation)
Дистрибутив Virtuozzo основан на операционной системе [CloudLinux](https://www.cloudlinux.com/) с патчами для ядра RHEL7, утилитами управления и модифицированным установщиком.
Рекомендуется именно этот способ установки Virtuozzo.

Текущая последняя версия ISO-образа доступна по адресу: https://download.openvz.org/virtuozzo/releases/7.0/x86_64/iso/

После записи дистрибутива на носитель, можно приступать к настройке Virtuozzo.
Для этого необходимо загрузиться с носителя.

*Экран установки Virtuozzo после загрузки с носителя*
![Экран установки Virtuozzo](https://raw.githubusercontent.com/Amet13/virtuozzo-tutorial/master/images/vz-install/install-vz.png)

Установка Virtuozzo ничем не отличается от установки обычного Linux-дистрибутива.
Установщик Anaconda предложит установить дату и время, раскладку клавиатуры, языковые параметры.
Также необходимо будет произвести разметку диска и настроить сеть.
По умолчанию включен kdump, который позволяет в будущем выяснить причины сбоев в ядре, поэтому рекомендуется его не отключать.

*Экран установки параметров системы*
![Настройки системы](https://raw.githubusercontent.com/Amet13/virtuozzo-tutorial/master/images/vz-install/anaconda.png)

*Пример разметки для 20GB диска*
![Разметка диска](https://raw.githubusercontent.com/Amet13/virtuozzo-tutorial/master/images/vz-install/partitioning.png)

Необходимо для раздела `/` выделить не менее 8GB доступного дискового пространства.
Размер раздела `swap` равен примерно половине объема оперативной памяти.
Все остальное дисковое пространство выделяется под раздел `/vz` с файловой системой ext4.

*Настройки сетевого интерфейса и имени хоста*
![Настройки сети](https://raw.githubusercontent.com/Amet13/virtuozzo-tutorial/master/images/vz-install/network.png)

Также необходимо задать пароль пользователя `root` и создать локального пользователя, например `vzuser`.

*Установка пароля суперпользователя и создание локального пользователя*
![Настройки пользователей](https://raw.githubusercontent.com/Amet13/virtuozzo-tutorial/master/images/vz-install/user.png)

После установки необходимо перезагрузиться.

На этом установка Virtuozzo с помощью ISO-образа завершена.

*Меню загрузчика Grub*
![Grub](https://raw.githubusercontent.com/Amet13/virtuozzo-tutorial/master/images/vz-install/grub.png)

Первый вход в систему осуществляется от пользователя `vzuser`, по SSH.

Пример получения прав суперпользователя на сервере:
```
amet13@mint-17 ~ $ ssh vzuser@192.168.0.150
vzuser@192.168.0.150's password: пароль_пользователя_vzuser
[vzuser@virtuozzo ~]$ su -
Password: пароль_пользователя_root
[root@virtuozzo ~]#
```

### Установка Virtuozzo на заранее установленный дистрибутив

Поддерживаемые дистрибутивы:
* CloudLinux 7
* CentOS 7
* Scientific Linux 7
* прочие дистрибутивы, основанные на RHEL7

Установка пакетов на примере дистрибутива CentOS 7.

Пакет `virtuozzo-release` содержит метаинформацию и yum-репозитории, необходимые для установки пакетов:
```
[root@virtuozzo ~]# yum localinstall https://download.openvz.org/virtuozzo/releases/7.0/x86_64/os/Packages/v/virtuozzo-release-7.0.0-10.vz7.x86_64.rpm
```

Установка необходимых RPM-пакетов:
```
[root@virtuozzo ~]# yum install prlctl prl-disp-service vzkernel ploop
```

В качестве зависимостей также установятся такие пакеты как `criu`, `libvirt`, `lvm2`, `nfs-utils`, `quota`, `vcmmd`, `vzctl`, `vztt` и другие.

По окончании установки пакетов необходимо перезагрузиться:
```
[root@virtuozzo ~]# reboot
```

В меню загрузчика должен появиться новый пункт `Virtuozzo 7`.
Необходимо загрузиться с этого ядра.

*Меню загрузчика Grub после установки Virtuozzo*
![Grub](https://raw.githubusercontent.com/Amet13/virtuozzo-tutorial/master/images/vz-install/grub-vz.png)

### Подготовительные действия
На сервере важно всегда обновлять программное обеспечение, так как в новых версиях не только могут добавлять новые возможности, но и исправлять уязвимости.
Указанная ниже команда обновляет все существующие в системе пакеты:
```
[root@virtuozzo ~]# yum update
```
Для сервера очень важно, чтобы было установлено правильное время.
Чтобы синхронизировать время с интернетом необходимо установить пакет `ntp`.

Установка корректной временной зоны:
```
[root@virtuozzo ~]# timedatectl set-timezone Europe/Moscow
[root@virtuozzo ~]# date
Tue Aug  4 14:52:54 MSK 2015
```
Установка `ntp` и синхронизация времени с удаленными серверами:
```
[root@virtuozzo ~]# yum install ntp
[root@virtuozzo ~]# systemctl start ntpd
[root@virtuozzo ~]# systemctl enable ntpd
[root@virtuozzo ~]# ntpdate -q  0.pool.ntp.org  1.pool.ntp.org
server 91.236.251.5, stratum 2, offset 0.002229, delay 0.05281
server 82.193.117.90, stratum 1, offset -0.020269, delay 0.04845
server 78.26.196.124, stratum 2, offset 0.003866, delay 0.05913
server 217.175.0.36, stratum 3, offset -0.003749, delay 0.06514
server 79.142.192.4, stratum 2, offset 0.006668, delay 0.05772
server 195.138.69.242, stratum 2, offset 0.005080, delay 0.05731
server 91.236.251.12, stratum 2, offset 0.002247, delay 0.05368
server 91.198.10.20, stratum 2, offset 0.003745, delay 0.05481
 4 Aug 14:54:56 ntpdate[2804]: adjust time server 91.236.251.5 offset 0.002229 sec
```

## Управление шаблонами гостевых ОС
На данный момент Virtuozzo поддерживает такие гостевые ОС:
* CentOS 7 (x86_64)
* CentOS 6 (x86_64)
* Ubuntu 14.04 LTS (x86_64)
* Debian 8 (x86_64)

Просмотр списка уже имеющихся локальных шаблонов:
```
[root@virtuozzo ~]# vzpkg list -O --with-summary
centos-6-x86_64                    :Centos 6 (for AMD64/Intel EM64T) Virtuozzo Template
centos-5-x86                       :Centos 5 (for ix86) Virtuozzo Template
```

Установка всех доступных шаблонов:
```
[root@virtuozzo ~]# vzpkg list --available --with-summary | xargs vzpkg install template
```

После этого можно увидеть список доступных локально шаблонов гостевых ОС:
```
[root@virtuozzo ~]# vzpkg list -O --with-summary
centos-6-x86_64                    :Centos 6 (for AMD64/Intel EM64T) Virtuozzo Template
centos-5-x86                       :Centos 5 (for ix86) Virtuozzo Template
centos-7-x86_64                    :Centos 7 (for AMD64/Intel EM64T) Virtuozzo Template
ubuntu-14.04-x86_64                :Ubuntu 14.04 (for AMD64/Intel EM64T) Virtuozzo Template
debian-8.0-x86_64                  :Debian 8.0 (for AMD64/Intel EM64T) Virtuozzo Template
```

Обновление кэша шаблонов:
```
[root@virtuozzo ~]# vzpkg update cache
```

## Создание и настройка контейнеров
### Конфигурационные файлы
В старых версиях OpenVZ основным идентификатором контейнера является CTID, который вручную указывался при создании контейнера.
Сейчас в этом нет необходимости, на смену CTID пришел UUID, который создается автоматически.
Однако существует возможность указания UUID вручную.

Каждый контейнер имеет свой конфигурационный файл, который хранится в каталоге `/etc/vz/conf/`.
Именуются конфиги по UUID контейнера.
Например, для контейнера с `UUID = {3d32522a-80af-4773-b9fa-ea4915dee4b3}`, конфиг будет называться `3d32522a-80af-4773-b9fa-ea4915dee4b3.conf`.

При создании контейнера можно использовать типовую конфигурацию.
Типовые файлы конфигураций находятся в том же каталоге `/etc/vz/conf/`:
```
[root@virtuozzo ~]# ls /etc/vz/conf/ | grep sample
ve-basic.conf-sample
ve-confixx.conf-sample
ve-vswap.1024MB.conf-sample
ve-vswap.2048MB.conf-sample
ve-vswap.256MB.conf-sample
ve-vswap.512MB.conf-sample
ve-vswap.plesk.conf-sample
vps.vzpkgtools.conf-sample
```

В этих конфигурационных файлах описаны контрольные параметры ресурсов, выделенное дисковое пространство, оперативная память и т.д.
Например, при использовании конфига `ve-vswap.512MB.conf-sample`, создается контейнер с дисковым пространством 10GB, оперативной памятью 512MB и swap 512MB:
```
[root@virtuozzo ~]# grep "DISKSPACE\|PHYSPAGES\|SWAPPAGES\|DISKINODES" /etc/vz/conf/ve-vswap.512MB.conf-sample
PHYSPAGES="131072:131072"
SWAPPAGES="131072"
DISKSPACE="10485760:10485760"
DISKINODES="655360:655360"
```

Это удобно, так как существует возможность создавать свои конфигурационные файлы для различных вариаций контейнеров.
Создадим свой конфигурационный файл, на базе уже существующего `vswap.512MB`.
Исправим в нем только значения `PHYSPAGES`, `SWAPPAGES`, `DISKSPACE`, `DISKINODES`:
```
[root@virtuozzo ~]# cp /etc/vz/conf/ve-vswap.512MB.conf-sample /etc/vz/conf/ve-vswap.1GB.conf-sample
[root@virtuozzo ~]# vim /etc/vz/conf/ve-vswap.1GB.conf-sample
PHYSPAGES="262144:262144"
SWAPPAGES="262144"
DISKSPACE="20971520:20971520"
DISKINODES="1310720:1310720"
```
Таким образом, при использовании этого конфигурационного файла, будет создаваться контейнер, которому будет доступно 20GB выделенного дискового пространства, 1GB оперативной памяти и 1GB swap.

Установка конфигурационного файла шаблона на примере `vswap.1GB`:
```
[root@virtuozzo ~]# prlctl set first --applyconfig vswap.1GB
The CT has been successfully configured.
```

### Создание контейнера
В качестве параметра к идентификатору контейнера может использоваться любое имя:
```
[root@virtuozzo ~]# CT=first
[root@virtuozzo ~]# prlctl create $CT --ostemplate debian-8.0-x86_64 --vmtype=ct
Creating the Virtuozzo Container...
The Container has been successfully created.
```

Таким образом был создан контейнер с именем `first` на базе шаблона `debian-8.0-x86_64`.

Теперь можно просмотреть список имеющихся в системе контейнеров:
```
[root@virtuozzo ~]# prlctl list -a
UUID                                    STATUS       IP_ADDR         T  NAME
{3d32522a-80af-4773-b9fa-ea4915dee4b3}  stopped      -               CT first
```

Если же при создании контейнера не указывать желаемый шаблон, то Virtuozzo будет использовать шаблон по умолчанию.
Конфигурационный файл, в котором указаны директивы по умолчанию `/etc/vz/vz.conf`.
По умолчанию, используется шаблон `centos-6` и конфигурационный файл `basic`:
```
[root@virtuozzo ~]# grep "CONFIGFILE\|DEF_OSTEMPLATE" /etc/vz/vz.conf
CONFIGFILE="basic"
DEF_OSTEMPLATE=".centos-6"
```

Если планируется создание большого количества однотипных контейнеров, основываясь на одном и том же конфиге, то значения можно исправить на нужные.

### Настройка контейнера
Контейнер создан, его можно запускать.
Но перед первым запуском необходимо установить его IP адреса, hostname, указать DNS сервера и задать пароль суперпользователя.

Добавление IP адресов:
```
[root@virtuozzo ~]# prlctl set first --ipadd 192.168.0.161/24
[root@virtuozzo ~]# prlctl set first --ipadd fe80::20c:29ff:fe01:fb08
```

Установка DNS сервера и hostname:
```
[root@virtuozzo ~]# prlctl set first --nameserver 192.168.0.1
[root@virtuozzo ~]# prlctl set first --hostname first.virtuozzo.localhost
```

Установка поискового домена (если требуется):
```
[root@virtuozzo ~]# prlctl set first --searchdomain 192.168.0.1
```

Установка пароля суперпользователя:
```
[root@virtuozzo ~]# prlctl set first --userpasswd root:p0oT
```

Пароль будет установлен в контейнер, в файл `/etc/shadow` и не будет сохранен в конфигурационный файл контейнера.
Если же пароль будет утерян или забыт, то можно будет просто задать новый.

Для запуска контейнера при старте хост-ноды добавляем:
```
[root@virtuozzo ~]# prlctl set first --onboot yes
```

### Запуск и вход
После настроек нового контейнера. его можно запустить:
```
[root@virtuozzo ~]# prlctl start first
Starting the CT...
The CT has been successfully started.
```

Проверяем сетевые интерфейсы внутри гостевой ОС:
```
[root@virtuozzo ~]# prlctl exec first ifconfig | grep "lo\|venet" -A 1
lo        Link encap:Local Loopback
          inet addr:127.0.0.1  Mask:255.0.0.0
--
venet0    Link encap:UNSPEC  HWaddr 00-00-00-00-00-00-00-00-00-00-00-00-00-00-00-00
          inet addr:127.0.0.1  P-t-P:127.0.0.1  Bcast:0.0.0.0  Mask:255.255.255.255
--
venet0:0  Link encap:UNSPEC  HWaddr 00-00-00-00-00-00-00-00-00-00-00-00-00-00-00-00
          inet addr:192.168.0.161  P-t-P:192.168.0.161  Bcast:192.168.0.255  Mask:255.255.255.0
```

Также проверим корректность hostname:
```
[root@virtuozzo ~]# prlctl exec first hostname
first.virtuozzo.localhost
```

Проверяем доступность контейнера в сети и корректность пароля суперпользователя:
```
[root@virtuozzo ~]# ssh root@192.168.0.161
root@192.168.0.161's password: p0oT
root@first:~#
```

Вход в контейнер напрямую с хост-ноды:
```
[root@virtuozzo ~]# prlctl enter first
entered into CT
root@first:/#
```

Выход из контейнера:
```
root@first:/# exit
logout
[root@virtuozzo ~]#
```

## Управление контейнерами
### Управление состоянием контейнера
Статус контейнера:
```
[root@virtuozzo ~]# prlctl status first
CT first exist running
[root@virtuozzo ~]# prlctl status second
CT second exist stopped
```

По выводу команды можно наблюдать, что контейнер `first` существует и запущен, а контейнер `second` существует и остановлен.

Остановка контейнера:
```
[root@virtuozzo ~]# prlctl stop first
Stopping the CT...
The CT has been successfully stopped.
```

Иногда нужно выключить контейнер как можно быстрее, например если контейнер был подвержен взлому.
Для того чтобы срочно выключить контейнер, нужно использовать ключ `--kill`:
```
[root@virtuozzo ~]# prlctl stop first --kill
Stopping the CT...
The CT has been forcibly stopped
```

Перезапуск контейнера:
```
[root@virtuozzo ~]# prlctl restart first
Restarting the CT...
The CT has been successfully restarted.
```

Для удаления контейнера его нужно сначала остановить:
```
[root@virtuozzo ~]# prlctl stop
Stopping the CT...
The CT has been successfully stopped.
[root@virtuozzo ~]# prlctl delete first
Removing the CT...
The CT has been successfully removed.
```

Команда выполняет удаление частной области сервера и переименовывает файл конфигурации, дописывая к нему `.destroyed`.

### Клонирование контейнера
Virtuozzo позволяет клонировать контейнеры:
```
[root@virtuozzo ~]# prlctl clone first --name second
Clone the first CT to CT second...
The CT has been successfully cloned.
[root@virtuozzo ~]# prlctl list -a
UUID                                    STATUS       IP_ADDR         T  NAME
{3d32522a-80af-4773-b9fa-ea4915dee4b3}  running      192.168.0.161   CT first
{54bc2ba6-b040-469e-9fda-b0eabda822d4}  stopped      192.168.0.161   CT second
```

При клонировании контейнера необходимо помнить о смене IP адреса, иначе при попытке запуска будет наблюдаться ошибка:
```
[root@virtuozzo ~]# prlctl start second
Starting the CT...
Failed to start the CT: PRL_ERR_VZCTL_OPERATION_FAILED
```

Сначала нужно удалить старые IP адреса:
```
[root@virtuozzo ~]# prlctl set second --ipdel 192.168.0.161/24
[root@virtuozzo ~]# prlctl set second --ipdel fe80::20c:29ff:fe01:fb08
```

Затем добавить новые:
```
[root@virtuozzo ~]# prlctl set second --ipadd 192.168.0.162/24
[root@virtuozzo ~]# prlctl set second --ipadd fe80::20c:29ff:fe01:fb09
```
Смена hostname:
```
[root@virtuozzo ~]# prlctl set second --hostname second.virtuozzo.localhost
The CT has been successfully configured.
```

После этого контейнер можно запустить:
```
[root@virtuozzo ~]# prlctl start second
Starting the CT...
The CT has been successfully started.
```

### Запуск команд в контейнере с хост-ноды
Пример запуска команды в контейнере:
```
[root@virtuozzo ~]# prlctl exec first cat /etc/issue
Debian GNU/Linux 8 \n \l
```

Иногда бывает нужно выполнить команду на нескольких контейнерах.
Для этого можно использовать команду:
```
[root@virtuozzo ~]# CMD="cat /etc/issue"
[root@virtuozzo ~]# for i in `prlctl list -o name -H`; do echo "CT $i"; prlctl exec $i $CMD; done
CT first
Debian GNU/Linux 8 \n \l

CT second
Debian GNU/Linux 8 \n \l
```

### Расширенная информация о контейнерах
Подробная информация о контейнере:
```
[root@virtuozzo ~]# prlctl list -i first
Autostop: suspend
Autocompact: on
Undo disks: off
Boot order:
EFI boot: off
Allow select boot device: off
External boot device:
Remote display: mode=off address=0.0.0.0
Remote display state: stopped
Hardware:
  cpu cpus=unlimited VT-x accl=high mode=32 cpuunits=1000 ioprio=4
  memory 512Mb
  video 0Mb 3d acceleration=highest vertical sync=yes
  memory_quota auto
  hdd0 (+) image='/vz/private/3d32522a-80af-4773-b9fa-ea4915dee4b3/root.hdd' type='expanded' 10240Mb mnt=/
  venet0 (+) type='routed' ips='192.168.0.161/255.255.255.0 FE80:0:0:0:20C:29FF:FE01:FB08/64 '
Host Shared Folders: (-)
Features:
Encrypted: no
Faster virtual machine: on
Adaptive hypervisor: off
Disabled Windows logo: on
Auto compress virtual disks: on
Nested virtualization: off
PMU virtualization: off
Offline management: (-)
Hostname: first.virtuozzo.localhost
DNS Servers: 192.168.0.1
```

Существует также возможность просмотра дополнительной информации о контейнерах:
```
[root@virtuozzo ~]# prlctl list -o type,status,name,hostname,dist,ip
T  STATUS       NAME                             HOSTNAME                         DIST            IP_ADDR
CT running      second                           second.virtuozzo.localhost       debian          192.168.0.162 FE80:0:0:0:20C:29FF:FE01:FB09
CT running      first                            first.virtuozzo.localhost        debian          192.168.0.161 FE80:0:0:0:20C:29FF:FE01:FB08
```

Список всех доступных полей:
```
[root@virtuozzo ~]# prlctl list -L
uuid                 UUID
envid                ENVID
status               STATUS
name                 NAME
dist                 DIST
owner                OWNER
system-flags         SYSTEM_FLAGS
description          DESCRIPTION
numproc              NPROC
ip                   IP_ADDR
ip_configured        IP_ADDR
hostname             HOSTNAME
netif                NETIF
mac                  MAC
features             FEATURES
location             LOCATION
iolimit              IOLIMIT
netdev               NETDEV
type                 T
ha_enable            HA_ENABLE
ha_prio              HA_PRIO
-                    -
```

## Управление ресурсами
Доступные контейнеру ресурсы контролируются с помощью набора параметров управления ресурсами.
Все эти параметры можно редактировать в файлах шаблонов, в каталоге `/etc/vz/conf/`.
Их можно установить вручную, редактируя соответствующие конфиги или используя утилиты Virtuozzo.

Параметры контроля ресурсов условно разделяют на группы:
* дисковые квоты
* процессор
* операции ввода/вывода
* память
* сеть

### Дисковые квоты
Администратор сервера Virtuozzo может устанавливать дисковые квоты, в терминах дискового пространства и количества inodes, число которых примерно равно количеству файлов.
Это первый уровень дисковой квоты.
В дополнение к этому, администратор может использовать обычные утилиты внутри окружения, для настроек стандартных дисковых квот UNIX для пользователей и групп.

Для использования дисковых квот, соответствующая директива должна присутствовать в конфигурационном файле Virtuozzo:
```
[root@virtuozzo ~]# grep DISK_QUOTA /etc/vz/vz.conf
DISK_QUOTA=yes
```

Основные параметры:
* `DISKSPACE` — общий размер дискового пространства (задается в Kb)
* `DISKINODES` — общее число дисковых inodes
* `QUOTATIME` — время (в секундах) на которое контейнер может превысить значение soft предела

Параметры записываются в конфигурационный файл в виде:
```
COMMAND="softlimit:hardlimit"
```
где:
* `COMMAND` — команда (`DISKSPACE` или `DISKINODES`)
* `softlimit` — значение которое превышать нежелательно, после пересечения этого предела наступает grace период, по истечении которого, дисковое пространство или inodes прекратят свое существование
* `hardlimit` — значение которое превысить нельзя

Например, запись:
```
DISKSPACE="19922944:20971520"
DISKINODES="1300000:1310720"
QUOTATIME="600"
```
означает, что задается `softlimit` для дискового пространства равным ~19G и `hardlimit` равный 20G, то же самое с inodes 1300000 и 1310720 соответственно.

Если размер занятого дискового пространства или inodes будет выше `softlimit`, то в течении 600 сек (10 мин), в случае не освобождения дискового пространства или inodes, они прекратят свое существование.

Аналогично, можно установить эти параметры с помощью `vzctl`:
```
[root@virtuozzo ~]# vzctl set first --diskspace 5G:6G --save
Resize the image /vz/private/3d32522a-80af-4773-b9fa-ea4915dee4b3/root.hdd to 6291456K
dumpe2fs 1.42.9 (28-Dec-2013)
[root@virtuozzo ~]# vzctl set first --diskinodes 10000:110000 --save
```

### Процессор
Планировщик процессора в Virtuozzo также двухуровневый.
На первом уровне планировщик решает, какому контейнеру дать квант процессорного времени, базируясь на значении параметра `CPUUNITS` для контейнера.
На втором уровне стандартный планировщик GNU/Linux решает, какому процессу в выбранном контейнере дать квант времени, базируясь на стандартных приоритетах процесса.

Основными параметрами управления CPU являются:
* `CPUUNITS` — гарантируемое минимальное количество времени процессора, которое получит соответствующий контейнер
* `CPUMASK` — привязка контейнера к конкретным процессорам, по умолчанию нагрузка распределяется на все процессоры
* `CPULIMIT` — верхний лимит процессорного времени в процентах
* `CPUS` — количество используемых процессорных (ядер) контейнером
* `NODEMASK` — привязка ядер NUMA-систем к контейнеру

Параметр `CPUUNITS` указывает процессорное время доступное для контейнера.
По умолчанию для каждого контейнера это значение равно 1000.
То есть, если для контейнера `first` установить значение 2000, а для контейнера `second` оставить значение 1000, то при равных условиях контейнер `first` получит ровно в два раза больше процессорного времени.
```
[root@virtuozzo ~]# prlctl set first --cpuunits 2000
set cpuunits 2000
```

Если система многопроцессорная, то установка параметра `CPUMASK` может пригодиться для привязки контейнера к конкретным процессорам.
В случае восьмипроцессорной системы можно привязать контейнер к процессорам 0-3, 6, 7:
```
[root@virtuozzo ~]# prlctl set first --cpumask 0-3,6,7
set cpu mask 0-3,6,7
```

Верхний лимит процессорного времени, который задается параметром `CPULIMIT` является долей общей мощности процессора в процентах:
```
[root@virtuozzo ~]# prlctl set first --cpulimit 15
set cpulimit 15%
```

Существует также возможность задания `CPULIMIT` в абсолютных значениях (MHz):
```
[root@virtuozzo ~]# prlctl set first --cpulimit 600m
set cpulimit 600Mhz
```

В параметре `CPUS` задается число доступных для контейнера процессорных ядер.
Контейнер по умолчанию получает в использование все процессорные ядра:
```
[root@virtuozzo ~]# CPUINFO="grep processor /proc/cpuinfo"
[root@virtuozzo ~]# prlctl exec first $CPUINFO
processor	: 0
processor	: 1
processor	: 2
processor	: 3
```

Установим для контейнера лимит в 2 процессорных ядра:
```
[root@virtuozzo ~]# prlctl set first --cpus 2
set cpus(4): 2
[root@virtuozzo ~]# prlctl exec first $CPUINFO
processor	: 0
processor	: 1
```

Для систем архитектуры NUMA существует возможность привязки контейнера к процессорам NUMA-нод:
```
[root@virtuozzo ~]# vzctl set first --nodemask 0 --save
```

Аналогично все параметры можно вручную прописать в конфигурационный файл контейнера:
```
CPUUNITS="2000"
CPUMASK="0-3,6,7"
CPULIMIT="15"
CPULIMIT_MHZ="600"
CPUS="2"
NODEMASK="0"
```

Утилиты контроля ресурсов процессора, гарантируют любому контейнеру количество времени центрального процессора, которое собственно и получает этот контейнер.
При этом контейнер может потреблять больше времени, чем определено этой величиной, если нет другого конкурирующего с ним за время CPU сервера.

### Операции ввода/вывода
В Virtuozzo существует возможность управления дисковыми операциями ввода/вывода.
Можно устанавливать значения таких параметров как:
* `IOPRIO`
* `IOLIMIT`
* `IOPSLIMIT`

Параметр `IOPRIO` указывает приоритет операция ввода вывода для контейнера.
По умолчанию для всех контейнеров установлен равный приоритет (значение 4).

Изменение значения параметра можно регулировать от 0 (максимальный приоритет) до 7:
```
[root@virtuozzo ~]# prlctl set first --ioprio 6
set ioprio 6
```

Параметр `IOLIMIT` позволяет ограничивать пропускную способность операций ввода/вывода.
По умолчанию параметр имеет значение 0, то есть отсутствие лимитов.

Установка значения в MB/s:
```
[root@virtuozzo ~]# prlctl set first --iolimit 20
Set up iolimit: 20971520
```

Существует возможность указания префиксов метрических значений:
* `G` — гигабайт
* `M` — мегабайт
* `K` — килобайт
* `B` — байт

Максимальная пропускная способность дисковых операций ввода/вывода составляет 2GB/s.

Помимо ограничения пропускной способности операций ввода/вывода, существует возможность ограничения количества операций ввода/вывода в секунду.

Параметр `IOPSLIMT` позволяет установить численное значение операций ввода/вывода в секунду, например 300:
```
[root@virtuozzo ~]# prlctl set first --iopslimit 300
set IOPS limit 300
```

По умолчанию значение этого параметра равно 0, что означает отсутствие лимитов.

Параметры можно указать вручную в конфигурационном файле контейнера:
```
IOPRIO="6"
IOLIMIT="20971520"
IOPSLIMIT="300"
```

Проверка ограничения пропускной способностей операций ввода/вывода на примере `IOLIMIT`.

Значение `IOLIMIT` равно 0:
```
root@first:/# dd if=/dev/zero of=test bs=1048576 count=10
10+0 records in
10+0 records out
10485760 bytes (10 MB) copied, 0.210523 s, 49.8 MB/s
```

Значение `IOLIMIT` равно 500K:
```
root@first:/# dd if=/dev/zero of=test bs=1048576 count=10
10+0 records in
10+0 records out
10485760 bytes (10 MB) copied, 17.4388 s, 601 kB/s
```

### Память
В Virtuozzo используется управление памятью четвертого поколения с помощью vcmmd.
В прошлом же использовалось управление памятью с помощью:
* VSwap (третье поколение)
* SLM (второе поколение)
* User Beancounters (первое поколение)

С пользовательской стороны управление памятью с помощью VSwap и vcmmd ничем не отличаются, однако с точки зрения реализации, vcmmd уже находится в ванильном ядре и не требует патчей со стороны разработчиков Virtuozzo.

Ограничение физической памяти и swap задаются в конфигурационном файле контейнера параметрами `PHYSPAGES` и `SWAPPAGES`.
Значения устанавливаются в блоках, например:
```
PHYSPAGES="262144:262144"
SWAPPAGES="262144:262144"
```
равняются значениям в 1024MB (262144 блок / 256 = 1024MB).

С помощью `prlctl` значения параметров можно указывать в метрической системе:
```
[root@virtuozzo ~]# prlctl set first --memsize 1G --swappages 1G
Set the memsize parameter to 1024Mb.
Set swappages 262144
```

Overcommiting — возможность использования большего числа ресурсов, чем выдано контейнеру.

Значение `VM_OVERCOMMIT` указывает число, во сколько раз больше памяти сможет использовать контейнер в случае необходимости.
По умолчанию значение `VM_OVERCOMMIT` равно 1.5.
То есть для контейнера установлено, с 1024MB оперативной памяти и 1024MB swap, суммарно доступно 2048MB памяти, в случае необходимости контейнер сможет использовать (2048MB * 1.5 = 3072MB) памяти.

Для изменения значения достаточно прописать параметр в конфигурационный файл контейнера и перезапустить его:
```
VM_OVERCOMMIT="2"
```

Также возможна установка параметра с помощью `vzctl`:
```
[root@virtuozzo ~]# vzctl set first --vm_overcommit 2 --save
```

При использовании значения 2 для ранее упомянутого контейнера с 2048MB памяти, будет доступно (2048MB * 2 = 4096MB) памяти.
Естественно, если если эти ресурсы доступны на хост-ноде.

### Мониторинг ресурсов
С помощью утилиты `vznetstat` можно увидеть входящий и исходящий трафик (в байтах и пакетах) для всех контейнеров:
```
[root@virtuozzo ~]# vznetstat
UUID                                 Net.Class     Input(bytes) Input(pkts)        Output(bytes) Output(pkts)
0                                    0                244486        3024              1567749        2491
54bc2ba6-b040-469e-9fda-b0eabda822d4 0                     0           0                    0           0
4730cba8-deed-4168-9f9e-34373e618026 0                     0           0                    0           0
3d32522a-80af-4773-b9fa-ea4915dee4b3 0               2925512       49396             49398885       49254
```

Для конкретного контейнера можно воспользоваться ключом `-v`:
```
[root@virtuozzo ~]# vznetstat -v 3d32522a-80af-4773-b9fa-ea4915dee4b3
UUID                                 Net.Class     Input(bytes) Input(pkts)        Output(bytes) Output(pkts)
3d32522a-80af-4773-b9fa-ea4915dee4b3 0               2925512       49396             49398885       49254
```

Утилита `vzstat` позволяет узнать информацию по нагрузке на контейнер, занятым ресурсам и состоянии сети:
```
[root@virtuozzo ~]# vzstat -p 3d32522a-80af-4773-b9fa-ea4915dee4b3 -t
loadavg		0 0 0
CTNum		3
procs		289 1 288 0 0 0 0
CPU		16 0 2 3 95
sched latency	372 9
Mem		989 360 0
Mem latency	1 0
  ZONE0 (DMA): size 15MB, act 4MB, inact 4MB, free 4MB (0/0/1)
  ZONE1 (DMA32): size 1007MB, act 243MB, inact 274MB, free 355MB (43/54/64)
  Mem lat (ms): A0 1, K0 0, U0 1, K1 0, U1 0
  Slab pages: 62MB/62MB (ino 22MB, de 0MB, bh 1MB, pb 0MB)
Swap		952 952 0.000 0.000
Net stats	0.382 5949 5.542 5820
if br0 stats	0.171 2975 2.771 2910
if lo stats	0.000 0 0.000 0
if virbr1-nic stats	0.000 0 0.000 0
if enp0s3 stats	0.211 2975 2.771 2910
if virbr1 stats	0.000 0 0.000 0
Disks stats	0.000 0.000

    CTID ST   %VM    %KM        PROC     CPU     SOCK FCNT MLAT IP
```

`vzpid` позволяет узнать к какому контейнеру принадлежит процесс, это может быть полезно при просмотре списка процессов с хост-ноды и поиска "процесса-грузчика":
```
[root@virtuozzo ~]# top
top - 20:43:26 up 33 min,  1 user,  load average: 0.00, 0.01, 0.05
Tasks: 178 total,   1 running, 176 sleeping,   1 stopped,   0 zombie
%Cpu(s):  1.7 us,  3.6 sy,  0.0 ni, 88.5 id,  0.0 wa,  0.0 hi,  6.2 si,  0.0 st
KiB Mem :  1013704 total,   382912 free,   138656 used,   492136 buff/cache
KiB Swap:   975868 total,   975868 free,        0 used.   688028 avail Mem

    PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
   5625 33        20   0  364432   6232   1284 S  26.2  0.6   0:03.20 apache2
...
[root@virtuozzo ~]# vzpid 5625
Pid	VEID	Name
5625	3d32522a-80af-4773-b9fa-ea4915dee4b3	apache2
```

Утилита `vzps` аналогична утилите `ps`, она позволяет вывести список процессов и их состояние для конкретного контейнера:
```
[root@virtuozzo ~]# vzps aufx -E 3d32522a-80af-4773-b9fa-ea4915dee4b3
    USER     PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
       0    2432  0.0  0.0      0     0 ?        S    20:10   0:00 [kthreadd/3d3252]
       0    2433  0.0  0.0      0     0 ?        S    20:10   0:00  \_ [khelper]
       0    2420  0.0  0.3  28168  3136 ?        Ss   20:10   0:00 init -z
     101    3088  0.0  0.1  26168  1448 ?        Ss   20:10   0:00  \_ /lib/systemd/systemd-networkd
       0    3117  0.0  0.1  28856  1620 ?        Ss   20:10   0:00  \_ /lib/systemd/systemd-journald
       0    3135  0.0  0.1  38916  1624 ?        Ss   20:10   0:00  \_ /lib/systemd/systemd-udevd
       0    3376  0.0  0.3  55156  3128 ?        Ss   20:10   0:00  \_ /usr/sbin/sshd -D
     102    3380  0.0  0.1  25732  1092 ?        Ss   20:10   0:00  \_ /lib/systemd/systemd-resolved
       0    3382  0.0  0.1  25884  1120 ?        Ss   20:10   0:00  \_ /usr/sbin/cron -f
       0    3388  0.0  0.1 182848  1884 ?        Ssl  20:10   0:00  \_ /usr/sbin/rsyslogd -n
       0    3433  0.0  0.0  12648   840 ?        Ss+  20:10   0:00  \_ /sbin/agetty --noclear tty2 linux
       0    3434  0.0  0.0  12648   840 ?        Ss+  20:10   0:00  \_ /sbin/agetty --noclear --keep-baud console 115200 38400 9600 linux
       0    3508  0.0  0.0  20200   956 ?        Ss   20:10   0:00  \_ /usr/sbin/xinetd -pidfile /run/xinetd.pid -stayalive -inetd_compat -inetd_ipv6
       0    3617  0.0  0.1  65452  1164 ?        Ss   20:10   0:00  \_ /usr/sbin/saslauthd -a pam -c -m /var/run/saslauthd -n 2
       0    3625  0.0  0.0  65452   836 ?        S    20:10   0:00  |   \_ /usr/sbin/saslauthd -a pam -c -m /var/run/saslauthd -n 2
       0    3755  0.0  0.2  73496  2724 ?        Ss   20:10   0:00  \_ /usr/sbin/apache2 -k start
      33    5747  0.2  0.5 363364  5300 ?        Sl   20:46   0:00  |   \_ /usr/sbin/apache2 -k start
       0    4074  0.0  0.2  36144  2388 ?        Ss   20:10   0:00  \_ /usr/lib/postfix/master
     105    4081  0.0  0.2  38208  2316 ?        S    20:10   0:00      \_ pickup -l -t unix -u -c
     105    4082  0.0  0.2  38256  2336 ?        S    20:10   0:00      \_ qmgr -l -t unix -u

```

Для утилиты `top` также существует аналог `vztop`.
Пример просмотра списка процессов отсортированных по нагрузке на процессор для контейнера `first`:
```
[root@virtuozzo ~]# vztop -E 3d32522a-80af-4773-b9fa-ea4915dee4b3 -o %CPU -b
vztop - 21:13:45 up  1:03,  1 user,  load average: 0.01, 0.04, 0.32
Tasks:  20 total,   0 running,  20 sleeping,   0 stopped,   0 zombie
%Cpu(s):  0.3 us,  0.7 sy,  0.0 ni, 98.5 id,  0.1 wa,  0.0 hi,  0.5 si,  0.0 st
KiB Mem :  1013704 total,   378752 free,   136600 used,   498352 buff/cache
KiB Swap:   975868 total,   975868 free,        0 used.   691636 avail Mem

                                    CTID     PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
    3d32522a-80af-4773-b9fa-ea4915dee4b3    5747 33        20   0  364424   6304   1280 S  40.0  0.6   0:03.37 apache2
    3d32522a-80af-4773-b9fa-ea4915dee4b3    2420 root      20   0   28168   3136   1908 S   0.0  0.3   0:00.32 systemd
    3d32522a-80af-4773-b9fa-ea4915dee4b3    2432 root      20   0       0      0      0 S   0.0  0.0   0:00.00 kthreadd/3d3252
    3d32522a-80af-4773-b9fa-ea4915dee4b3    2433 root      20   0       0      0      0 S   0.0  0.0   0:00.00 khelper
    3d32522a-80af-4773-b9fa-ea4915dee4b3    3088 101       20   0   26168   1448   1204 S   0.0  0.1   0:00.06 systemd-network
    3d32522a-80af-4773-b9fa-ea4915dee4b3    3117 root      20   0   28856   1620   1356 S   0.0  0.2   0:00.12 systemd-journal
    3d32522a-80af-4773-b9fa-ea4915dee4b3    3135 root      20   0   38916   1624   1132 S   0.0  0.2   0:00.04 systemd-udevd
    3d32522a-80af-4773-b9fa-ea4915dee4b3    3376 root      20   0   55156   3128   2460 S   0.0  0.3   0:00.01 sshd
    3d32522a-80af-4773-b9fa-ea4915dee4b3    3380 102       20   0   25732   1092    896 S   0.0  0.1   0:00.00 systemd-resolve
    3d32522a-80af-4773-b9fa-ea4915dee4b3    3382 root      20   0   25884   1120    900 S   0.0  0.1   0:00.01 cron
    3d32522a-80af-4773-b9fa-ea4915dee4b3    3388 root      20   0  182848   1884   1412 S   0.0  0.2   0:00.02 rsyslogd
    3d32522a-80af-4773-b9fa-ea4915dee4b3    3433 root      20   0   12648    840    692 S   0.0  0.1   0:00.00 agetty
    3d32522a-80af-4773-b9fa-ea4915dee4b3    3434 root      20   0   12648    840    692 S   0.0  0.1   0:00.00 agetty
    3d32522a-80af-4773-b9fa-ea4915dee4b3    3508 root      20   0   20200    956    756 S   0.0  0.1   0:00.00 xinetd
    3d32522a-80af-4773-b9fa-ea4915dee4b3    3617 root      20   0   65452   1164    328 S   0.0  0.1   0:00.00 saslauthd
    3d32522a-80af-4773-b9fa-ea4915dee4b3    3625 root      20   0   65452    836      0 S   0.0  0.1   0:00.00 saslauthd
    3d32522a-80af-4773-b9fa-ea4915dee4b3    3755 root      20   0   73496   2724   1512 S   0.0  0.3   0:00.58 apache2
    3d32522a-80af-4773-b9fa-ea4915dee4b3    4074 root      20   0   36144   2388   1848 S   0.0  0.2   0:00.06 master
    3d32522a-80af-4773-b9fa-ea4915dee4b3    4081 105       20   0   38208   2316   1776 S   0.0  0.2   0:00.04 pickup
    3d32522a-80af-4773-b9fa-ea4915dee4b3    4082 105       20   0   38256   2336   1792 S   0.0  0.2   0:00.02 qmgr
```

## Миграция контейнеров
В текущей версии Virtuozzo пока недоступна возможность онлайн-миграции контейнеров без их отключения.

Пример оффлайн миграции контейнера с хост-ноды `vz-source` на `vz-dest`.

Устанавливаем на `vz-source` последние версии `vzmigrate`, `rsync` и `screen`:
```
[root@vz-source ~]# yum localinstall http://download.openvz.org/virtuozzo/releases/7.0-beta2/x86_64/os/Packages/r/rsync-3.0.9-15.vz7.7.x86_64.rpm
[root@vz-source ~]# yum localinstall https://download.openvz.org/virtuozzo/releases/7.0-beta2/x86_64/os/Packages/v/vzmigrate-7.0.10-1.vz7.x86_64.rpm
```

Аналогично устанавливаем на `vz-dest` последние версии `vzmigrate` и `rsync`.

Создаем и копируем SSH-ключ с `vz-source` на `vz-dest` для беспарольной аутентификации:
```
[root@vz-source ~]# cd /root && ssh-keygen
[root@vz-source ~]# ssh-copy-id root@192.168.0.180
```

Останавливаем контейнер перед миграцией:
```
[root@vz-source ~]# prlctl stop third
Stopping the CT...
The CT has been successfully stopped.
```

Запускаем миграцию в `screen`:
```
[root@vz-source ~]# screen
[root@vz-source ~]# vzmigrate 192.168.0.180 third
Connection to destination node (192.168.0.180) is successfully established
Moving/copying CT 4730cba8-deed-4168-9f9e-34373e618026 -> CT 4730cba8-deed-4168-9f9e-34373e618026, [], [] ...
locking 4730cba8-deed-4168-9f9e-34373e618026
Checking bindmounts
Check cluster ID
Checking keep dir for private area copy
Checking technologies
Checking templates for CT
Checking IP addresses on destination node
Check target CT name: third
Checking RATE parameters in config
Checking ploop format 2
copy CT private /vz/private/4730cba8-deed-4168-9f9e-34373e618026
Successfully completed
```

Проверяем на `vz-dest` наличие только что смигрированного контейнера, если он смигрирован, то запускаем его:
```
[root@vz-dest ~]# prlctl list third
UUID                                    STATUS       IP_ADDR         T  NAME
{4730cba8-deed-4168-9f9e-34373e618026}  stopped      192.168.0.163   CT third
[root@vz-dest ~]# prlctl start third
Starting the CT...
The CT has been successfully started.
```

## Ссылки
* https://openvz.org/History
* https://openvz.org/Quick_installation
* https://openvz.org/OpenVZ_with_upstream_kernel
* https://openvz.org/Packages
* https://openvz.org/Roadmap
* https://openvz.org/Category:HOWTO
* http://docs.openvz.org/virtuozzo_7_users_guide.webhelp/
* https://openvz.org/Books

## Лицензия
![CC BY-SA 4.0](https://licensebuttons.net/l/by-sa/4.0/88x31.png)

[Attribution-ShareAlike 4.0 International (CC BY-SA 4.0)](https://creativecommons.org/licenses/by-sa/4.0/deed.ru)
